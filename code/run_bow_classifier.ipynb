{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vocab_mismatch_utils import *\n",
    "from data_formatter_utils import *\n",
    "from datasets import DatasetDict\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Load modules, mainly huggingface basic model handlers.\n",
    "# Make sure you install huggingface and other packages properly.\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"../huggingface_cache/\" # Not overload common dir \n",
    "                                                           # if run in shared resources.\n",
    "\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric\n",
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from transformers.trainer_utils import is_main_process, EvaluationStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(inoculation_data_path, eval_data_path=None, \n",
    "                inoculation_step_sample_size=1.0, \n",
    "                eval_sample_limit=-1, seed=42):\n",
    "    \"\"\"\n",
    "    eval_data_path is not needed if it is a saved_to_disk \n",
    "    huggingface dataset.\n",
    "    \n",
    "    return type is already a huggingface dataset.\n",
    "    \"\"\"\n",
    "    pd_format = True\n",
    "    if inoculation_data_path.split(\".\")[-1] != \"tsv\":\n",
    "        if len(inoculation_data_path.split(\".\")) > 1:\n",
    "            logger.info(f\"***** Loading pre-loaded datasets from the disk directly! *****\")\n",
    "            pd_format = False\n",
    "            datasets = DatasetDict.load_from_disk(inoculation_data_path)\n",
    "            inoculation_step_sample_size = int(len(datasets[\"train\"]) * inoculation_step_sample_size)\n",
    "            logger.info(f\"***** Inoculation Sample Count: %s *****\"%(inoculation_step_sample_size))\n",
    "            # this may not always start for zero inoculation\n",
    "            datasets[\"train\"] = datasets[\"train\"].shuffle(seed=seed)\n",
    "            inoculation_train_df = datasets[\"train\"].select(range(inoculation_step_sample_size))\n",
    "            eval_df = datasets[\"validation\"]\n",
    "            datasets[\"validation\"] = datasets[\"validation\"].shuffle(seed=seed)\n",
    "            if eval_sample_limit != -1:\n",
    "                datasets[\"validation\"] = datasets[\"validation\"].select(range(eval_sample_limit))\n",
    "        else:\n",
    "            logger.info(f\"***** Loading downloaded huggingface datasets: {inoculation_data_path}! *****\")\n",
    "            pd_format = False\n",
    "            if inoculation_data_path in [\"sst3\", \"cola\", \"mnli\", \"snli\", \"mrps\", \"qnli\"]:\n",
    "                pass\n",
    "            raise NotImplementedError()\n",
    "    else:\n",
    "        train_df = pd.read_csv(inoculation_data_path, delimiter=\"\\t\")\n",
    "        eval_df = pd.read_csv(eval_data_path, delimiter=\"\\t\")\n",
    "        inoculation_step_sample_size = int(len(train_df) * inoculation_step_sample_size)\n",
    "        logger.info(f\"***** Inoculation Sample Count: %s *****\"%(inoculation_step_sample_size))\n",
    "        # this may not always start for zero inoculation\n",
    "        inoculation_train_df = train_df.sample(n=inoculation_step_sample_size, \n",
    "                                               replace=False, \n",
    "                                               random_state=seed) # seed here could not a little annoying.\n",
    "    if pd_format:\n",
    "        datasets = {}\n",
    "        datasets[\"train\"] = Dataset.from_pandas(inoculation_train_df)\n",
    "        datasets[\"validation\"] = Dataset.from_pandas(eval_df)\n",
    "    else:\n",
    "        datasets = {}\n",
    "        datasets[\"train\"] = inoculation_train_df\n",
    "        datasets[\"validation\"] = eval_df\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_CONFIG = {\n",
    "    \"sst3\": (\"text\", None),\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"snli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\")\n",
    "}\n",
    "original_vocab = load_bert_vocab(\"../data-files/bert_vocab.txt\")\n",
    "original_tokenizer = transformers.BertTokenizer(\n",
    "    vocab_file=\"../data-files/bert_vocab.txt\")\n",
    "max_length = 128\n",
    "per_device_train_batch_size = 128\n",
    "per_device_eval_batch_size = 128\n",
    "no_cuda = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count() if not no_cuda else 1 # 1 means just on cpu\n",
    "seed = 42\n",
    "lr = 1e-3\n",
    "num_train_epochs = 1000\n",
    "task_name = \"qnli\"\n",
    "sentence1_key, sentence2_key = TASK_CONFIG[task_name]\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if n_gpu > 0 and not no_cuda:\n",
    "    torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:27:05 - INFO - __main__ - ***** Inoculation Sample Count: 104743 *****\n",
      "02/22/2021 13:27:05 - INFO - __main__ - ***** Train Sample Count (Verify): 104743 *****\n",
      "02/22/2021 13:27:05 - INFO - __main__ - ***** Valid Sample Count (Verify): 5463 *****\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "datasets = get_dataset(f\"../data-files/{task_name}/{task_name}-train.tsv\", \n",
    "                       f\"../data-files/{task_name}/{task_name}-dev.tsv\")\n",
    "logger.info(f\"***** Train Sample Count (Verify): %s *****\"%(len(datasets[\"train\"])))\n",
    "logger.info(f\"***** Valid Sample Count (Verify): %s *****\"%(len(datasets[\"validation\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104743/104743 [01:40<00:00, 1046.33it/s]\n"
     ]
    }
   ],
   "source": [
    "train_input_features = []\n",
    "train_label_ids = []\n",
    "for (ex_index, example) in enumerate(tqdm(datasets[\"train\"])):\n",
    "    bow_feature = torch.zeros(len(original_vocab))\n",
    "    if sentence2_key is None:\n",
    "        sentence_combined = example[sentence1_key]\n",
    "    else:\n",
    "        sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "    sentence_combined = sentence_combined[:max_length]\n",
    "    sentence_tokens = original_tokenizer.tokenize(sentence_combined)\n",
    "    for t in sentence_tokens:\n",
    "        bow_feature[original_vocab[t]] += 1\n",
    "    train_input_features.append(bow_feature)\n",
    "    train_label_ids.append(example[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_input_features = torch.stack(train_input_features, dim=0)\n",
    "train_input_features = torch.tensor(train_input_features, dtype=torch.float)\n",
    "train_label_ids = torch.tensor(train_label_ids, dtype=torch.long)\n",
    "train_data = TensorDataset(train_input_features, train_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5463/5463 [00:04<00:00, 1130.13it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_input_features = []\n",
    "validation_label_ids = []\n",
    "for (ex_index, example) in enumerate(tqdm(datasets[\"validation\"])):\n",
    "    bow_feature = torch.zeros(len(original_vocab))\n",
    "    if sentence2_key is None:\n",
    "        sentence_combined = example[sentence1_key]\n",
    "    else:\n",
    "        sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "    sentence_combined = sentence_combined[:max_length]\n",
    "    sentence_tokens = original_tokenizer.tokenize(sentence_combined)\n",
    "    for t in sentence_tokens:\n",
    "        bow_feature[original_vocab[t]] += 1\n",
    "    validation_input_features.append(bow_feature)\n",
    "    validation_label_ids.append(example[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "validation_input_features = torch.stack(validation_input_features, dim=0)\n",
    "validation_input_features = torch.tensor(validation_input_features, dtype=torch.float)\n",
    "validation_label_ids = torch.tensor(validation_label_ids, dtype=torch.long)\n",
    "validation_data = TensorDataset(validation_input_features, validation_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=per_device_train_batch_size*n_gpu)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=per_device_eval_batch_size*n_gpu, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BOWClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(BOWClassifier, self).__init__()\n",
    "        self.classifier = nn.Linear(vocab_size, num_labels)\n",
    "    def forward(self, x, labels=None):\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BOWClassifier(len(validation_label_ids.unique()), len(original_vocab))\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "if n_gpu > 0 and not no_cuda:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:14 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.49442   0.27868   0.35645      2702\n",
      "           1    0.50533   0.72112   0.59424      2761\n",
      "\n",
      "    accuracy                        0.50229      5463\n",
      "   macro avg    0.49987   0.49990   0.47534      5463\n",
      "weighted avg    0.49993   0.50229   0.47663      5463\n",
      "\n",
      "Macro-F1:  0.47534468493177295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:17 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.56423   0.52665   0.54479      2702\n",
      "           1    0.56511   0.60196   0.58295      2761\n",
      "\n",
      "    accuracy                        0.56471      5463\n",
      "   macro avg    0.56467   0.56430   0.56387      5463\n",
      "weighted avg    0.56468   0.56471   0.56408      5463\n",
      "\n",
      "Macro-F1:  0.5638733057850795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:20 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.55943   0.52258   0.54038      2702\n",
      "           1    0.56108   0.59725   0.57860      2761\n",
      "\n",
      "    accuracy                        0.56031      5463\n",
      "   macro avg    0.56025   0.55991   0.55949      5463\n",
      "weighted avg    0.56026   0.56031   0.55969      5463\n",
      "\n",
      "Macro-F1:  0.5594857695329023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:23 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.54843   0.57624   0.56199      2702\n",
      "           1    0.56364   0.53568   0.54930      2761\n",
      "\n",
      "    accuracy                        0.55574      5463\n",
      "   macro avg    0.55604   0.55596   0.55565      5463\n",
      "weighted avg    0.55612   0.55574   0.55558      5463\n",
      "\n",
      "Macro-F1:  0.5556480206553427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:26 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.54890   0.57328   0.56083      2702\n",
      "           1    0.56342   0.53894   0.55091      2761\n",
      "\n",
      "    accuracy                        0.55592      5463\n",
      "   macro avg    0.55616   0.55611   0.55587      5463\n",
      "weighted avg    0.55624   0.55592   0.55581      5463\n",
      "\n",
      "Macro-F1:  0.5558662801156329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:29 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.54359   0.59771   0.56936      2702\n",
      "           1    0.56380   0.50887   0.53493      2761\n",
      "\n",
      "    accuracy                        0.55281      5463\n",
      "   macro avg    0.55370   0.55329   0.55215      5463\n",
      "weighted avg    0.55381   0.55281   0.55196      5463\n",
      "\n",
      "Macro-F1:  0.5521480359791383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:34 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.55082   0.50740   0.52822      2702\n",
      "           1    0.55245   0.59507   0.57297      2761\n",
      "\n",
      "    accuracy                        0.55171      5463\n",
      "   macro avg    0.55164   0.55124   0.55060      5463\n",
      "weighted avg    0.55165   0.55171   0.55084      5463\n",
      "\n",
      "Macro-F1:  0.5505974477656235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:38 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.54702   0.55329   0.55014      2702\n",
      "           1    0.55788   0.55161   0.55473      2761\n",
      "\n",
      "    accuracy                        0.55244      5463\n",
      "   macro avg    0.55245   0.55245   0.55243      5463\n",
      "weighted avg    0.55251   0.55244   0.55246      5463\n",
      "\n",
      "Macro-F1:  0.5524319548070381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:42 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.54587   0.57476   0.55994      2702\n",
      "           1    0.56112   0.53205   0.54620      2761\n",
      "\n",
      "    accuracy                        0.55318      5463\n",
      "   macro avg    0.55349   0.55341   0.55307      5463\n",
      "weighted avg    0.55357   0.55318   0.55300      5463\n",
      "\n",
      "Macro-F1:  0.5530702446296019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:46 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.54817   0.51591   0.53155      2702\n",
      "           1    0.55205   0.58385   0.56751      2761\n",
      "\n",
      "    accuracy                        0.55025      5463\n",
      "   macro avg    0.55011   0.54988   0.54953      5463\n",
      "weighted avg    0.55013   0.55025   0.54972      5463\n",
      "\n",
      "Macro-F1:  0.5495297908218135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:49 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.54419   0.56514   0.55447      2702\n",
      "           1    0.55777   0.53676   0.54707      2761\n",
      "\n",
      "    accuracy                        0.55080      5463\n",
      "   macro avg    0.55098   0.55095   0.55077      5463\n",
      "weighted avg    0.55105   0.55080   0.55073      5463\n",
      "\n",
      "Macro-F1:  0.5507657843499157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:53 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.54161   0.56847   0.55471      2702\n",
      "           1    0.55615   0.52916   0.54232      2761\n",
      "\n",
      "    accuracy                        0.54860      5463\n",
      "   macro avg    0.54888   0.54881   0.54851      5463\n",
      "weighted avg    0.54896   0.54860   0.54845      5463\n",
      "\n",
      "Macro-F1:  0.5485145755464773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:31:56 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.54024   0.58882   0.56349      2702\n",
      "           1    0.55878   0.50960   0.53306      2761\n",
      "\n",
      "    accuracy                        0.54878      5463\n",
      "   macro avg    0.54951   0.54921   0.54827      5463\n",
      "weighted avg    0.54961   0.54878   0.54811      5463\n",
      "\n",
      "Macro-F1:  0.5482702696193118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:32:00 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.54233   0.55477   0.54848      2702\n",
      "           1    0.55428   0.54183   0.54799      2761\n",
      "\n",
      "    accuracy                        0.54823      5463\n",
      "   macro avg    0.54830   0.54830   0.54823      5463\n",
      "weighted avg    0.54837   0.54823   0.54823      5463\n",
      "\n",
      "Macro-F1:  0.5482334350610969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:32:03 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.54219   0.57069   0.55608      2702\n",
      "           1    0.55708   0.52843   0.54238      2761\n",
      "\n",
      "    accuracy                        0.54933      5463\n",
      "   macro avg    0.54964   0.54956   0.54923      5463\n",
      "weighted avg    0.54972   0.54933   0.54915      5463\n",
      "\n",
      "Macro-F1:  0.549227816826354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:32:07 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.53940   0.54219   0.54079      2702\n",
      "           1    0.54969   0.54690   0.54829      2761\n",
      "\n",
      "    accuracy                        0.54457      5463\n",
      "   macro avg    0.54454   0.54455   0.54454      5463\n",
      "weighted avg    0.54460   0.54457   0.54458      5463\n",
      "\n",
      "Macro-F1:  0.5445416754126284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:32:10 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.53738   0.56403   0.55038      2702\n",
      "           1    0.55158   0.52481   0.53786      2761\n",
      "\n",
      "    accuracy                        0.54421      5463\n",
      "   macro avg    0.54448   0.54442   0.54412      5463\n",
      "weighted avg    0.54455   0.54421   0.54405      5463\n",
      "\n",
      "Macro-F1:  0.5441205568170027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:32:13 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.53738   0.55329   0.54522      2702\n",
      "           1    0.54979   0.53386   0.54171      2761\n",
      "\n",
      "    accuracy                        0.54347      5463\n",
      "   macro avg    0.54359   0.54358   0.54347      5463\n",
      "weighted avg    0.54366   0.54347   0.54345      5463\n",
      "\n",
      "Macro-F1:  0.5434675355067201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:32:17 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.53206   0.54663   0.53925      2702\n",
      "           1    0.54410   0.52952   0.53671      2761\n",
      "\n",
      "    accuracy                        0.53798      5463\n",
      "   macro avg    0.53808   0.53808   0.53798      5463\n",
      "weighted avg    0.53815   0.53798   0.53797      5463\n",
      "\n",
      "Macro-F1:  0.5379793101118933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:32:20 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.53368   0.56588   0.54931      2702\n",
      "           1    0.54850   0.51612   0.53182      2761\n",
      "\n",
      "    accuracy                        0.54073      5463\n",
      "   macro avg    0.54109   0.54100   0.54056      5463\n",
      "weighted avg    0.54117   0.54073   0.54047      5463\n",
      "\n",
      "Macro-F1:  0.5405620309454928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:32:23 - INFO - __main__ - ***** Evaluation Interval Hit *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.53368   0.57476   0.55346      2702\n",
      "           1    0.54994   0.50851   0.52842      2761\n",
      "\n",
      "    accuracy                        0.54128      5463\n",
      "   macro avg    0.54181   0.54164   0.54094      5463\n",
      "weighted avg    0.54190   0.54128   0.54080      5463\n",
      "\n",
      "Macro-F1:  0.5409361921641647\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-a9e618f1670b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# pbar = tqdm(train_dataloader, desc=\"Iteration\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "for _ in range(int(num_train_epochs)):\n",
    "    \n",
    "    model.train()\n",
    "    # pbar = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if torch.cuda.is_available() and not no_cuda:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        input_features, label_ids = batch\n",
    "\n",
    "        if torch.cuda.is_available() and not no_cuda:\n",
    "            input_features = input_features.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "\n",
    "        loss, _ = model(input_features, labels=label_ids)\n",
    "\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        # pbar.set_postfix({'train_loss': loss.tolist()})\n",
    "\n",
    "        if global_step % 500 == 0:\n",
    "            logger.info(\"***** Evaluation Interval Hit *****\")\n",
    "            model.eval()\n",
    "            all_logits = []\n",
    "            all_label_ids = []\n",
    "            with torch.no_grad():\n",
    "                # pbar = tqdm(validation_dataloader, desc=\"Iteration\")\n",
    "                for step, batch in enumerate(validation_dataloader):\n",
    "                    if torch.cuda.is_available() and not no_cuda:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                    input_features, label_ids = batch\n",
    "                    \n",
    "                    if torch.cuda.is_available() and not no_cuda:\n",
    "                        input_features = input_features.to(device)\n",
    "                        label_ids = label_ids.to(device)\n",
    "                    \n",
    "                    loss, logits = model(input_features, labels=label_ids)\n",
    "                    logits = F.softmax(logits, dim=-1)\n",
    "                    logits = logits.detach().cpu().numpy()\n",
    "                    label_ids = label_ids.to('cpu').numpy()\n",
    "                    outputs = np.argmax(logits, axis=1)\n",
    "                    all_logits.append(outputs)\n",
    "                    all_label_ids.append(label_ids)\n",
    "                    \n",
    "            all_logits = np.concatenate(all_logits, axis=0)\n",
    "            all_label_ids = np.concatenate(all_label_ids, axis=0)\n",
    "            result_to_save = classification_report(all_label_ids, all_logits, digits=5, output_dict=True)\n",
    "            print(classification_report(all_label_ids, all_logits, digits=5))\n",
    "            print(\"Macro-F1: \", result_to_save[\"macro avg\"][\"f1-score\"])\n",
    "                    \n",
    "        global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:32:28 - INFO - __main__ - ***** Loading pre-loaded datasets from the disk directly! *****\n",
      "02/22/2021 13:32:29 - INFO - __main__ - ***** Inoculation Sample Count: 104743 *****\n",
      "Loading cached shuffled indices for dataset at ../data-files/qnli-corrupted/train/cache-1554dfc1dcdbbd75.arrow\n",
      "Loading cached shuffled indices for dataset at ../data-files/qnli-corrupted/validation/cache-04fc1ef0f3bc5901.arrow\n",
      "02/22/2021 13:32:29 - INFO - __main__ - ***** Train Sample Count (Verify): 104743 *****\n",
      "02/22/2021 13:32:29 - INFO - __main__ - ***** Valid Sample Count (Verify): 5463 *****\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "corrupt_datasets = get_dataset(f\"../data-files/{task_name}-corrupted\")\n",
    "logger.info(f\"***** Train Sample Count (Verify): %s *****\"%(len(datasets[\"train\"])))\n",
    "logger.info(f\"***** Valid Sample Count (Verify): %s *****\"%(len(datasets[\"validation\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5463/5463 [00:06<00:00, 821.28it/s]\n"
     ]
    }
   ],
   "source": [
    "corrupt_validation_input_features = []\n",
    "corrupt_validation_label_ids = []\n",
    "for (ex_index, example) in enumerate(tqdm(corrupt_datasets[\"validation\"])):\n",
    "    bow_feature = torch.zeros(len(original_vocab))\n",
    "    if sentence2_key is None:\n",
    "        sentence_combined = example[sentence1_key]\n",
    "    else:\n",
    "        sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "    sentence_combined = sentence_combined[:max_length]\n",
    "    sentence_tokens = original_tokenizer.tokenize(sentence_combined)\n",
    "    for t in sentence_tokens:\n",
    "        bow_feature[original_vocab[t]] += 1\n",
    "    corrupt_validation_input_features.append(bow_feature)\n",
    "    corrupt_validation_label_ids.append(example[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "corrupt_validation_input_features = torch.stack(corrupt_validation_input_features, dim=0)\n",
    "corrupt_validation_input_features = torch.tensor(corrupt_validation_input_features, dtype=torch.float)\n",
    "corrupt_validation_label_ids = torch.tensor(corrupt_validation_label_ids, dtype=torch.long)\n",
    "corrupt_validation_data = TensorDataset(corrupt_validation_input_features, corrupt_validation_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_validation_dataloader = DataLoader(corrupt_validation_data, batch_size=per_device_eval_batch_size*n_gpu, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2021 13:32:47 - INFO - __main__ - ***** Evaluation With Corrupt Data *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.48950   0.92339   0.63983      2702\n",
      "           1    0.43443   0.05759   0.10169      2761\n",
      "\n",
      "    accuracy                        0.48581      5463\n",
      "   macro avg    0.46196   0.49049   0.37076      5463\n",
      "weighted avg    0.46167   0.48581   0.36785      5463\n",
      "\n",
      "Macro-F1:  0.37076026696164865\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"***** Evaluation With Corrupt Data *****\")\n",
    "model.eval()\n",
    "all_logits = []\n",
    "all_label_ids = []\n",
    "with torch.no_grad():\n",
    "    # pbar = tqdm(validation_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(corrupt_validation_dataloader):\n",
    "        if torch.cuda.is_available() and not no_cuda:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        input_features, label_ids = batch\n",
    "\n",
    "        if torch.cuda.is_available() and not no_cuda:\n",
    "            input_features = input_features.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "\n",
    "        loss, logits = model(input_features, labels=label_ids)\n",
    "        logits = F.softmax(logits, dim=-1)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        outputs = np.argmax(logits, axis=1)\n",
    "        all_logits.append(outputs)\n",
    "        all_label_ids.append(label_ids)\n",
    "\n",
    "all_logits = np.concatenate(all_logits, axis=0)\n",
    "all_label_ids = np.concatenate(all_label_ids, axis=0)\n",
    "result_to_save = classification_report(all_label_ids, all_logits, digits=5, output_dict=True)\n",
    "print(classification_report(all_label_ids, all_logits, digits=5))\n",
    "print(\"Macro-F1: \", result_to_save[\"macro avg\"][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
