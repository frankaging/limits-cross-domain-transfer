{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vocab_mismatch_utils import *\n",
    "from data_formatter_utils import *\n",
    "from datasets import DatasetDict\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import operator\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Load modules, mainly huggingface basic model handlers.\n",
    "# Make sure you install huggingface and other packages properly.\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"../huggingface_cache/\" # Not overload common dir \n",
    "                                                           # if run in shared resources.\n",
    "\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric\n",
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from transformers.trainer_utils import is_main_process, EvaluationStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(inoculation_data_path, eval_data_path=None, test_data_path=None,\n",
    "                inoculation_step_sample_size=1.0, \n",
    "                eval_sample_limit=-1, seed=42):\n",
    "    \"\"\"\n",
    "    eval_data_path is not needed if it is a saved_to_disk \n",
    "    huggingface dataset.\n",
    "    \n",
    "    return type is already a huggingface dataset.\n",
    "    \"\"\"\n",
    "    pd_format = True\n",
    "    if inoculation_data_path.split(\".\")[-1] != \"tsv\":\n",
    "        if len(inoculation_data_path.split(\".\")) > 1:\n",
    "            logger.info(f\"***** Loading pre-loaded datasets from the disk directly! *****\")\n",
    "            pd_format = False\n",
    "            datasets = DatasetDict.load_from_disk(inoculation_data_path)\n",
    "            inoculation_step_sample_size = int(len(datasets[\"train\"]) * inoculation_step_sample_size)\n",
    "            logger.info(f\"***** Inoculation Sample Count: %s *****\"%(inoculation_step_sample_size))\n",
    "            # this may not always start for zero inoculation\n",
    "            datasets[\"train\"] = datasets[\"train\"].shuffle(seed=seed)\n",
    "            inoculation_train_df = datasets[\"train\"].select(range(inoculation_step_sample_size))\n",
    "            eval_df = datasets[\"validation\"]\n",
    "            datasets[\"validation\"] = datasets[\"validation\"].shuffle(seed=seed)\n",
    "            if eval_sample_limit != -1:\n",
    "                datasets[\"validation\"] = datasets[\"validation\"].select(range(eval_sample_limit))\n",
    "        else:\n",
    "            logger.info(f\"***** Loading downloaded huggingface datasets: {inoculation_data_path}! *****\")\n",
    "            pd_format = False\n",
    "            if inoculation_data_path in [\"sst3\", \"cola\", \"mnli\", \"snli\", \"mrps\", \"qnli\"]:\n",
    "                pass\n",
    "            raise NotImplementedError()\n",
    "    else:\n",
    "        train_df = pd.read_csv(inoculation_data_path, delimiter=\"\\t\")\n",
    "        eval_df = pd.read_csv(eval_data_path, delimiter=\"\\t\")\n",
    "        test_df = pd.read_csv(test_data_path, delimiter=\"\\t\")\n",
    "        inoculation_step_sample_size = int(len(train_df) * inoculation_step_sample_size)\n",
    "        logger.info(f\"***** Inoculation Sample Count: %s *****\"%(inoculation_step_sample_size))\n",
    "        # this may not always start for zero inoculation\n",
    "        inoculation_train_df = train_df.sample(n=inoculation_step_sample_size, \n",
    "                                               replace=False, \n",
    "                                               random_state=seed) # seed here could not a little annoying.\n",
    "    if pd_format:\n",
    "        datasets = {}\n",
    "        datasets[\"train\"] = Dataset.from_pandas(inoculation_train_df)\n",
    "        datasets[\"validation\"] = Dataset.from_pandas(eval_df)\n",
    "        datasets[\"test\"] = Dataset.from_pandas(test_df)\n",
    "    else:\n",
    "        datasets = {}\n",
    "        datasets[\"train\"] = inoculation_train_df\n",
    "        datasets[\"validation\"] = eval_df\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_CONFIG = {\n",
    "    \"sst3\": (\"text\", None),\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"snli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\")\n",
    "}\n",
    "# WARNING: you dont need BERT tokenizer\n",
    "# original_vocab = load_bert_vocab(\"../data-files/bert_vocab.txt\")\n",
    "# original_tokenizer = transformers.BertTokenizer(\n",
    "#     vocab_file=\"../data-files/bert_vocab.txt\")\n",
    "# Just use some basic white space tokenizor here!\n",
    "modified_basic_tokenizer = ModifiedBasicTokenizer()\n",
    "max_length = 128\n",
    "per_device_train_batch_size = 128\n",
    "per_device_eval_batch_size = 128\n",
    "no_cuda = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count() if not no_cuda else 1 # 1 means just on cpu\n",
    "seed = 42\n",
    "lr = 1e-3\n",
    "num_train_epochs = 10\n",
    "task_name = \"sst3\"\n",
    "sentence1_key, sentence2_key = TASK_CONFIG[task_name]\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if n_gpu > 0 and not no_cuda:\n",
    "    torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/15/2021 19:31:19 - INFO - __main__ - ***** Inoculation Sample Count: 159274 *****\n",
      "03/15/2021 19:31:19 - INFO - __main__ - ***** Train Sample Count (Verify): 159274 *****\n",
      "03/15/2021 19:31:19 - INFO - __main__ - ***** Valid Sample Count (Verify): 1100 *****\n",
      "03/15/2021 19:31:19 - INFO - __main__ - ***** Test Sample Count (Verify): 2210 *****\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "data_file_name = task_name if task_name != \"sst3\" else \"sst-tenary\"\n",
    "datasets = get_dataset(f\"../data-files/{data_file_name}/{data_file_name}-train.tsv\", \n",
    "                       f\"../data-files/{data_file_name}/{data_file_name}-dev.tsv\", \n",
    "                       f\"../data-files/{data_file_name}/{data_file_name}-test.tsv\")\n",
    "logger.info(f\"***** Train Sample Count (Verify): %s *****\"%(len(datasets[\"train\"])))\n",
    "logger.info(f\"***** Valid Sample Count (Verify): %s *****\"%(len(datasets[\"validation\"])))\n",
    "logger.info(f\"***** Test Sample Count (Verify): %s *****\"%(len(datasets[\"test\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoW preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159274/159274 [00:22<00:00, 6959.93it/s]\n",
      "100%|██████████| 1100/1100 [00:00<00:00, 2483.65it/s]\n",
      "100%|██████████| 2210/2210 [00:00<00:00, 2840.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# create the vocab file\n",
    "vocab_index = 0\n",
    "original_vocab = OrderedDict()\n",
    "if \"train\" in datasets:\n",
    "    for (ex_index, example) in enumerate(tqdm(datasets[\"train\"])):\n",
    "        if sentence2_key is None:\n",
    "            sentence_combined = example[sentence1_key]\n",
    "        else:\n",
    "            sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "        sentence_tokens = modified_basic_tokenizer.tokenize(sentence_combined)\n",
    "        for token in sentence_tokens:\n",
    "            if token not in original_vocab.keys():\n",
    "                original_vocab[token] = vocab_index\n",
    "                vocab_index += 1\n",
    "train_data_only = False\n",
    "if not train_data_only:\n",
    "    if \"validation\" in datasets:\n",
    "        for (ex_index, example) in enumerate(tqdm(datasets[\"validation\"])):\n",
    "            if sentence2_key is None:\n",
    "                sentence_combined = example[sentence1_key]\n",
    "            else:\n",
    "                sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "            sentence_tokens = modified_basic_tokenizer.tokenize(sentence_combined)\n",
    "            for token in sentence_tokens:\n",
    "                if token not in original_vocab.keys():\n",
    "                    original_vocab[token] = vocab_index\n",
    "                    vocab_index += 1\n",
    "\n",
    "    if \"test\" in datasets:\n",
    "        for (ex_index, example) in enumerate(tqdm(datasets[\"test\"])):\n",
    "            if sentence2_key is None:\n",
    "                sentence_combined = example[sentence1_key]\n",
    "            else:\n",
    "                sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "            sentence_tokens = modified_basic_tokenizer.tokenize(sentence_combined)\n",
    "            for token in sentence_tokens:\n",
    "                if token not in original_vocab.keys():\n",
    "                    original_vocab[token] = vocab_index\n",
    "                    vocab_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 457/159274 [00:00<01:25, 1859.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: Surprisingly, considering that Baird is a former film editor, the movie is rather choppy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 50465/159274 [00:15<00:34, 3194.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: achronological\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 100411/159274 [00:30<00:17, 3411.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: Show\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 150506/159274 [00:47<00:04, 2163.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: picked me up ,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159274/159274 [00:50<00:00, 3161.97it/s]\n",
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# BoW feature vectors for train split\n",
    "train_input_features = []\n",
    "train_label_ids = []\n",
    "for (ex_index, example) in enumerate(tqdm(datasets[\"train\"])):\n",
    "    bow_feature = torch.zeros(len(original_vocab))\n",
    "    if sentence2_key is None:\n",
    "        sentence_combined = example[sentence1_key]\n",
    "    else:\n",
    "        sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "    sentence_tokens = modified_basic_tokenizer.tokenize(sentence_combined)\n",
    "    sentence_tokens = sentence_tokens[:max_length]\n",
    "    if ex_index % 50000 == 0:\n",
    "        print(\"Example sentence: \" + sentence_combined)\n",
    "    for t in sentence_tokens:\n",
    "        bow_feature[original_vocab[t]] += 1\n",
    "    train_input_features.append(bow_feature)\n",
    "    train_label_ids.append(example[\"label\"])\n",
    "    \n",
    "train_input_features = torch.stack(train_input_features, dim=0)\n",
    "train_input_features = torch.tensor(train_input_features, dtype=torch.float)\n",
    "train_label_ids = torch.tensor(train_label_ids, dtype=torch.long)\n",
    "train_data = TensorDataset(train_input_features, train_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:00<00:00, 1651.96it/s]\n",
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# BoW feature vectors for validation split\n",
    "validation_input_features = []\n",
    "validation_label_ids = []\n",
    "for (ex_index, example) in enumerate(tqdm(datasets[\"validation\"])):\n",
    "    bow_feature = torch.zeros(len(original_vocab))\n",
    "    if sentence2_key is None:\n",
    "        sentence_combined = example[sentence1_key]\n",
    "    else:\n",
    "        sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "    sentence_tokens = modified_basic_tokenizer.tokenize(sentence_combined)\n",
    "    sentence_tokens = sentence_tokens[:max_length]\n",
    "    for t in sentence_tokens:\n",
    "        if t in original_vocab.keys():\n",
    "            bow_feature[original_vocab[t]] += 1\n",
    "    validation_input_features.append(bow_feature)\n",
    "    validation_label_ids.append(example[\"label\"])\n",
    "\n",
    "validation_input_features = torch.stack(validation_input_features, dim=0)\n",
    "validation_input_features = torch.tensor(validation_input_features, dtype=torch.float)\n",
    "validation_label_ids = torch.tensor(validation_label_ids, dtype=torch.long)\n",
    "validation_data = TensorDataset(validation_input_features, validation_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=per_device_train_batch_size*n_gpu)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=per_device_eval_batch_size*n_gpu, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoW Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BOWClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(BOWClassifier, self).__init__()\n",
    "        self.classifier = nn.Linear(vocab_size, num_labels)\n",
    "    def forward(self, x, labels=None):\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockBERTBOWClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(MockBERTBOWClassifier, self).__init__()\n",
    "        self.mock_bert = nn.Linear(vocab_size, vocab_size)\n",
    "        self.mock_activation = nn.Tanh()\n",
    "        self.classifier = nn.Linear(vocab_size, num_labels)\n",
    "    def forward(self, x, labels=None):\n",
    "        cls = self.mock_activation(self.mock_bert(x))\n",
    "        logits = self.classifier(cls)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some overriding fun stuffs!\n",
    "lr = 1e-3\n",
    "num_train_epochs = 10\n",
    "model = MockBERTBOWClassifier(len(validation_label_ids.unique()), len(original_vocab))\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "if n_gpu > 0 and not no_cuda:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/15/2021 19:53:24 - INFO - __main__ - ***** Evaluation Interval Hit *****\n",
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       428\n",
      "           1    0.40870   0.97297   0.57562       444\n",
      "           2    0.34884   0.06579   0.11070       228\n",
      "\n",
      "    accuracy                        0.40636      1100\n",
      "   macro avg    0.25251   0.34625   0.22877      1100\n",
      "weighted avg    0.23727   0.40636   0.25528      1100\n",
      "\n",
      "Macro-F1:  0.22877245428017234\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a9e618f1670b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# pbar.set_postfix({'train_loss': loss.tolist()})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "for _ in range(int(num_train_epochs)):\n",
    "    \n",
    "    model.train()\n",
    "    # pbar = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if torch.cuda.is_available() and not no_cuda:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        input_features, label_ids = batch\n",
    "\n",
    "        if torch.cuda.is_available() and not no_cuda:\n",
    "            input_features = input_features.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "\n",
    "        loss, _ = model(input_features, labels=label_ids)\n",
    "\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        # pbar.set_postfix({'train_loss': loss.tolist()})\n",
    "\n",
    "        if global_step % 500 == 0:\n",
    "            logger.info(\"***** Evaluation Interval Hit *****\")\n",
    "            model.eval()\n",
    "            all_logits = []\n",
    "            all_label_ids = []\n",
    "            with torch.no_grad():\n",
    "                # pbar = tqdm(validation_dataloader, desc=\"Iteration\")\n",
    "                for step, batch in enumerate(validation_dataloader):\n",
    "                    if torch.cuda.is_available() and not no_cuda:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                    input_features, label_ids = batch\n",
    "                    \n",
    "                    if torch.cuda.is_available() and not no_cuda:\n",
    "                        input_features = input_features.to(device)\n",
    "                        label_ids = label_ids.to(device)\n",
    "                    \n",
    "                    loss, logits = model(input_features, labels=label_ids)\n",
    "                    logits = F.softmax(logits, dim=-1)\n",
    "                    logits = logits.detach().cpu().numpy()\n",
    "                    label_ids = label_ids.to('cpu').numpy()\n",
    "                    outputs = np.argmax(logits, axis=1)\n",
    "                    all_logits.append(outputs)\n",
    "                    all_label_ids.append(label_ids)\n",
    "                    \n",
    "            all_logits = np.concatenate(all_logits, axis=0)\n",
    "            all_label_ids = np.concatenate(all_label_ids, axis=0)\n",
    "            result_to_save = classification_report(all_label_ids, all_logits, digits=5, output_dict=True)\n",
    "            print(classification_report(all_label_ids, all_logits, digits=5))\n",
    "            print(\"Macro-F1: \", result_to_save[\"macro avg\"][\"f1-score\"])\n",
    "                    \n",
    "        global_step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluations with corrupt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/15/2021 00:18:06 - INFO - __main__ - ***** Loading pre-loaded datasets from the disk directly! *****\n",
      "03/15/2021 00:18:06 - INFO - __main__ - ***** Inoculation Sample Count: 159274 *****\n",
      "03/15/2021 00:18:06 - INFO - __main__ - ***** Train Sample Count (Verify): 159274 *****\n",
      "03/15/2021 00:18:06 - INFO - __main__ - ***** Valid Sample Count (Verify): 1100 *****\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "corrupt_method = \"S3\"\n",
    "data_file_name = task_name if task_name != \"sst3\" else \"sst-tenary\"\n",
    "corrupt_datasets = get_dataset(f\"../data-files/{data_file_name}-corrupted-{corrupt_method}\")\n",
    "logger.info(f\"***** Train Sample Count (Verify): %s *****\"%(len(datasets[\"train\"])))\n",
    "logger.info(f\"***** Valid Sample Count (Verify): %s *****\"%(len(datasets[\"validation\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:00<00:00, 1194.33it/s]\n"
     ]
    }
   ],
   "source": [
    "corrupt_validation_input_features = []\n",
    "corrupt_validation_label_ids = []\n",
    "for (ex_index, example) in enumerate(tqdm(corrupt_datasets[\"validation\"])):\n",
    "    bow_feature = torch.zeros(len(original_vocab))\n",
    "    if sentence2_key is None:\n",
    "        sentence_combined = example[sentence1_key]\n",
    "    else:\n",
    "        sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "    sentence_tokens = modified_basic_tokenizer.tokenize(sentence_combined)\n",
    "    sentence_tokens = sentence_tokens[:max_length]\n",
    "    for t in sentence_tokens:\n",
    "        bow_feature[original_vocab[t]] += 1\n",
    "    corrupt_validation_input_features.append(bow_feature)\n",
    "    corrupt_validation_label_ids.append(example[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "corrupt_validation_input_features = torch.stack(corrupt_validation_input_features, dim=0)\n",
    "corrupt_validation_input_features = torch.tensor(corrupt_validation_input_features, dtype=torch.float)\n",
    "corrupt_validation_label_ids = torch.tensor(corrupt_validation_label_ids, dtype=torch.long)\n",
    "corrupt_validation_data = TensorDataset(corrupt_validation_input_features, corrupt_validation_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_validation_dataloader = DataLoader(corrupt_validation_data, batch_size=per_device_eval_batch_size*n_gpu, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/15/2021 00:18:12 - INFO - __main__ - ***** Evaluation With Corrupt Data *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.42553   0.04673   0.08421       428\n",
      "           1    0.38776   0.04279   0.07708       444\n",
      "           2    0.21016   0.92544   0.34253       228\n",
      "\n",
      "    accuracy                        0.22727      1100\n",
      "   macro avg    0.34115   0.33832   0.16794      1100\n",
      "weighted avg    0.36564   0.22727   0.13488      1100\n",
      "\n",
      "Macro-F1:  0.16794070045110934\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"***** Evaluation With Corrupt Data *****\")\n",
    "model.eval()\n",
    "all_logits = []\n",
    "all_label_ids = []\n",
    "with torch.no_grad():\n",
    "    # pbar = tqdm(validation_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(corrupt_validation_dataloader):\n",
    "        if torch.cuda.is_available() and not no_cuda:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        input_features, label_ids = batch\n",
    "\n",
    "        if torch.cuda.is_available() and not no_cuda:\n",
    "            input_features = input_features.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "\n",
    "        loss, logits = model(input_features, labels=label_ids)\n",
    "        logits = F.softmax(logits, dim=-1)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        outputs = np.argmax(logits, axis=1)\n",
    "        all_logits.append(outputs)\n",
    "        all_label_ids.append(label_ids)\n",
    "\n",
    "all_logits = np.concatenate(all_logits, axis=0)\n",
    "all_label_ids = np.concatenate(all_label_ids, axis=0)\n",
    "result_to_save = classification_report(all_label_ids, all_logits, digits=5, output_dict=True)\n",
    "print(classification_report(all_label_ids, all_logits, digits=5))\n",
    "print(\"Macro-F1: \", result_to_save[\"macro avg\"][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FrequencyBoW classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task setups\n",
    "task_name = \"sst3\"\n",
    "num_labels = 3\n",
    "FILENAME_CONFIG = {\n",
    "    \"sst3\" : \"sst-tenary\"\n",
    "}\n",
    "\n",
    "# let us corrupt SST3 in the same way as before\n",
    "train_df = pd.read_csv(os.path.join(external_output_dirname, FILENAME_CONFIG[task_name], \n",
    "                                    f\"{FILENAME_CONFIG[task_name]}-train.tsv\"), \n",
    "                       delimiter=\"\\t\")\n",
    "eval_df = pd.read_csv(os.path.join(external_output_dirname, FILENAME_CONFIG[task_name], \n",
    "                                   f\"{FILENAME_CONFIG[task_name]}-dev.tsv\"), \n",
    "                      delimiter=\"\\t\")\n",
    "test_df = pd.read_csv(os.path.join(external_output_dirname, FILENAME_CONFIG[task_name], \n",
    "                                   f\"{FILENAME_CONFIG[task_name]}-test.tsv\"), \n",
    "                      delimiter=\"\\t\")\n",
    "\n",
    "train_df = Dataset.from_pandas(train_df)\n",
    "eval_df = Dataset.from_pandas(eval_df)\n",
    "test_df = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing #10000 example...\n",
      "processing #20000 example...\n",
      "processing #30000 example...\n",
      "processing #40000 example...\n",
      "processing #50000 example...\n",
      "processing #60000 example...\n",
      "processing #70000 example...\n",
      "processing #80000 example...\n",
      "processing #90000 example...\n",
      "processing #100000 example...\n",
      "processing #110000 example...\n",
      "processing #120000 example...\n",
      "processing #130000 example...\n",
      "processing #140000 example...\n",
      "processing #150000 example...\n"
     ]
    }
   ],
   "source": [
    "modified_basic_tokenizer = ModifiedBasicTokenizer()\n",
    "label_vocab_map = {}\n",
    "token_frequency_map = {} # overwrite this everytime for a new dataset\n",
    "for i, example in enumerate(train_df):\n",
    "    if i % 10000 == 0 and i != 0:\n",
    "        print(f\"processing #{i} example...\")\n",
    "    original_sentence = example['text']\n",
    "    label = example['label']\n",
    "    if len(original_sentence.strip()) != 0:\n",
    "        tokens = modified_basic_tokenizer.tokenize(original_sentence)\n",
    "        if label not in label_vocab_map.keys():\n",
    "            label_vocab_map[label] = tokens\n",
    "        else:\n",
    "            for t in tokens:\n",
    "                label_vocab_map[label].append(t)\n",
    "        for t in tokens:\n",
    "            if t in token_frequency_map.keys():\n",
    "                token_frequency_map[t] = token_frequency_map[t] + 1\n",
    "            else:\n",
    "                token_frequency_map[t] = 1\n",
    "for i, example in enumerate(eval_df):\n",
    "    if i % 10000 == 0 and i != 0:\n",
    "        print(f\"processing #{i} example...\")\n",
    "    original_sentence = example['text']\n",
    "    label = example['label']\n",
    "    if len(original_sentence.strip()) != 0:\n",
    "        tokens = modified_basic_tokenizer.tokenize(original_sentence)\n",
    "        if label not in label_vocab_map.keys():\n",
    "            label_vocab_map[label] = tokens\n",
    "        else:\n",
    "            for t in tokens:\n",
    "                label_vocab_map[label].append(t)\n",
    "        for t in tokens:\n",
    "            if t in token_frequency_map.keys():\n",
    "                token_frequency_map[t] = token_frequency_map[t] + 1\n",
    "            else:\n",
    "                token_frequency_map[t] = 1\n",
    "for i, example in enumerate(test_df):\n",
    "    if i % 10000 == 0 and i != 0:\n",
    "        print(f\"processing #{i} example...\")\n",
    "    original_sentence = example['text']\n",
    "    label = example['label']\n",
    "    if len(original_sentence.strip()) != 0:\n",
    "        tokens = modified_basic_tokenizer.tokenize(original_sentence)\n",
    "        if label not in label_vocab_map.keys():\n",
    "            label_vocab_map[label] = tokens\n",
    "        else:\n",
    "            for t in tokens:\n",
    "                label_vocab_map[label].append(t)\n",
    "        for t in tokens:\n",
    "            if t in token_frequency_map.keys():\n",
    "                token_frequency_map[t] = token_frequency_map[t] + 1\n",
    "            else:\n",
    "                token_frequency_map[t] = 1\n",
    "task_token_frequency_map = sorted(token_frequency_map.items(), key=operator.itemgetter(1), reverse=True)\n",
    "task_token_frequency_map = OrderedDict(task_token_frequency_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training BoW with 1st order frequency bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq and bucket mappings\n",
    "freq_set = set([])\n",
    "for k, v in task_token_frequency_map.items():\n",
    "    freq_set.add(v)\n",
    "freq_set = list(freq_set)\n",
    "freq_set.sort()\n",
    "freq_bucket = np.logspace(math.log(freq_set[0], 10), math.log(freq_set[-1], 10), 25, endpoint=True)\n",
    "freq_bucket = freq_bucket[:-1]\n",
    "freq_bucket = [math.ceil(n) for n in freq_bucket]\n",
    "# finally the bucket is a map between freq and bucket number\n",
    "def find_bucket_number(freq, freq_bucket):\n",
    "    for i in range(len(freq_bucket)):\n",
    "        if freq > freq_bucket[i]:\n",
    "            continue\n",
    "        else:\n",
    "            return i+1\n",
    "    return len(freq_bucket)\n",
    "\n",
    "freq_bucket_map = {}\n",
    "for freq in freq_set:\n",
    "    bucket_num = find_bucket_number(freq, freq_bucket)\n",
    "    freq_bucket_map[freq] = bucket_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 428/159274 [00:00<01:13, 2169.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: This is one of the year's best films.\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 2., 0.,\n",
      "        0., 1., 1., 1., 1., 4.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 50743/159274 [00:14<00:39, 2717.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: there is plenty of room for editing, and a much shorter cut surely would have resulted in a smoother, more focused narrative without sacrificing any of the cultural intrigue\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 1., 2., 2., 0., 2., 4., 0., 1., 1., 2., 2.,\n",
      "        1., 1., 1., 1., 1., 8.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 100766/159274 [00:27<00:14, 3935.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: his name was, uh, Michael Zaidan, was supposed to have like written the screenplay or something\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 2., 2., 1., 0., 3., 0.,\n",
      "        2., 2., 0., 0., 0., 5.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 150737/159274 [00:41<00:02, 3516.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: They just don't work in concert.\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 2., 1.,\n",
      "        0., 1., 0., 0., 1., 2.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159274/159274 [00:43<00:00, 3646.28it/s]\n",
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# FBoW feature vectors for train split\n",
    "train_input_features = []\n",
    "train_label_ids = []\n",
    "for (ex_index, example) in enumerate(tqdm(train_df)):\n",
    "    bow_feature = torch.zeros(len(freq_bucket))\n",
    "    if sentence2_key is None:\n",
    "        sentence_combined = example[sentence1_key]\n",
    "    else:\n",
    "        sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "    sentence_tokens = modified_basic_tokenizer.tokenize(sentence_combined)\n",
    "    sentence_tokens = sentence_tokens[:max_length]\n",
    "    for t in sentence_tokens:\n",
    "        bow_feature[freq_bucket_map[token_frequency_map[t]]-1] += 1 # bucket count\n",
    "    if ex_index % 50000 == 0:\n",
    "        print(\"Example sentence: \" + sentence_combined)\n",
    "        print(bow_feature)\n",
    "    train_input_features.append(bow_feature)\n",
    "    train_label_ids.append(example[\"label\"])\n",
    "    \n",
    "train_input_features = torch.stack(train_input_features, dim=0)\n",
    "train_input_features = torch.tensor(train_input_features, dtype=torch.float)\n",
    "train_label_ids = torch.tensor(train_label_ids, dtype=torch.long)\n",
    "train_data = TensorDataset(train_input_features, train_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:00<00:00, 1562.76it/s]\n",
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# FBoW feature vectors for validation split\n",
    "validation_input_features = []\n",
    "validation_label_ids = []\n",
    "for (ex_index, example) in enumerate(tqdm(eval_df)):\n",
    "    bow_feature = torch.zeros(len(freq_bucket))\n",
    "    if sentence2_key is None:\n",
    "        sentence_combined = example[sentence1_key]\n",
    "    else:\n",
    "        sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "    sentence_tokens = modified_basic_tokenizer.tokenize(sentence_combined)\n",
    "    sentence_tokens = sentence_tokens[:max_length]\n",
    "    for t in sentence_tokens:\n",
    "        bow_feature[freq_bucket_map[token_frequency_map[t]]-1] += 1 # bucket count\n",
    "    validation_input_features.append(bow_feature)\n",
    "    validation_label_ids.append(example[\"label\"])\n",
    "\n",
    "validation_input_features = torch.stack(validation_input_features, dim=0)\n",
    "validation_input_features = torch.tensor(validation_input_features, dtype=torch.float)\n",
    "validation_label_ids = torch.tensor(validation_label_ids, dtype=torch.long)\n",
    "validation_data = TensorDataset(validation_input_features, validation_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=per_device_train_batch_size*n_gpu)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=per_device_eval_batch_size*n_gpu, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBOWClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(FBOWClassifier, self).__init__()\n",
    "        self.classifier = nn.Linear(vocab_size, num_labels)\n",
    "    def forward(self, x, labels=None):\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some overriding fun stuffs!\n",
    "lr = 1e-4\n",
    "num_train_epochs = 10\n",
    "model = FBOWClassifier(len(validation_label_ids.unique()), len(freq_bucket))\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "if n_gpu > 0 and not no_cuda:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [128 x 349], m2: [24 x 3] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-db6f536e4b6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mlabel_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-c88fd993446e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, labels)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [128 x 349], m2: [24 x 3] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "max_score = -1\n",
    "for _ in range(int(num_train_epochs)):\n",
    "    \n",
    "    model.train()\n",
    "    # pbar = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if torch.cuda.is_available() and not no_cuda:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        input_features, label_ids = batch\n",
    "\n",
    "        if torch.cuda.is_available() and not no_cuda:\n",
    "            input_features = input_features.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "\n",
    "        loss, _ = model(input_features, labels=label_ids)\n",
    "\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        # pbar.set_postfix({'train_loss': loss.tolist()})\n",
    "\n",
    "        if global_step % 500 == 0:\n",
    "            logger.info(\"***** Evaluation Interval Hit *****\")\n",
    "            model.eval()\n",
    "            all_logits = []\n",
    "            all_label_ids = []\n",
    "            with torch.no_grad():\n",
    "                # pbar = tqdm(validation_dataloader, desc=\"Iteration\")\n",
    "                for step, batch in enumerate(validation_dataloader):\n",
    "                    if torch.cuda.is_available() and not no_cuda:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                    input_features, label_ids = batch\n",
    "                    \n",
    "                    if torch.cuda.is_available() and not no_cuda:\n",
    "                        input_features = input_features.to(device)\n",
    "                        label_ids = label_ids.to(device)\n",
    "                    \n",
    "                    loss, logits = model(input_features, labels=label_ids)\n",
    "                    logits = F.softmax(logits, dim=-1)\n",
    "                    logits = logits.detach().cpu().numpy()\n",
    "                    label_ids = label_ids.to('cpu').numpy()\n",
    "                    outputs = np.argmax(logits, axis=1)\n",
    "                    all_logits.append(outputs)\n",
    "                    all_label_ids.append(label_ids)\n",
    "                    \n",
    "            all_logits = np.concatenate(all_logits, axis=0)\n",
    "            all_label_ids = np.concatenate(all_label_ids, axis=0)\n",
    "            result_to_save = classification_report(all_label_ids, all_logits, digits=5, output_dict=True)\n",
    "            print(classification_report(all_label_ids, all_logits, digits=5))\n",
    "            print(\"Macro-F1: \", result_to_save[\"macro avg\"][\"f1-score\"])\n",
    "            if result_to_save[\"macro avg\"][\"f1-score\"] > max_score:\n",
    "                max_score = result_to_save[\"macro avg\"][\"f1-score\"]\n",
    "                    \n",
    "        global_step += 1\n",
    "print(\"Best Macro-F1: \", max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training BoW with 1st and 2nd order frequency bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_order_bucket_index = {}\n",
    "index = 0\n",
    "for i in range(1, len(freq_bucket)+1):\n",
    "    for j in range(i+1, len(freq_bucket)+1):\n",
    "        second_order_bucket_index[(i,j)] = index\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 69/159274 [00:00<03:50, 689.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: This is one of the year's best films.\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 2., 0., 0., 1., 1., 1., 1., 4., 0., 0., 2., 2.,\n",
      "        2., 2., 8., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 4.,\n",
      "        1., 1., 4., 1., 4., 4.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 50129/159274 [00:40<01:27, 1242.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: there is plenty of room for editing, and a much shorter cut surely would have resulted in a smoother, more focused narrative without sacrificing any of the cultural intrigue\n",
      "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,  2.,\n",
      "         0.,  2.,  4.,  0.,  1.,  1.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  8.,\n",
      "         2.,  2.,  0.,  2.,  4.,  0.,  1.,  1.,  2.,  2.,  1.,  1.,  1.,  1.,\n",
      "         1.,  8.,  4.,  0.,  4.,  8.,  0.,  2.,  2.,  4.,  4.,  2.,  2.,  2.,\n",
      "         2.,  2., 16.,  0.,  4.,  8.,  0.,  2.,  2.,  4.,  4.,  2.,  2.,  2.,\n",
      "         2.,  2., 16.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  8.,  0.,  2.,  2.,  4.,  4.,  2.,  2.,  2.,  2.,  2., 16.,\n",
      "         0.,  4.,  4.,  8.,  8.,  4.,  4.,  4.,  4.,  4., 32.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,  2.,  1.,  1.,  1.,  1.,\n",
      "         1.,  8.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  8.,  4.,  2.,  2.,  2.,\n",
      "         2.,  2., 16.,  2.,  2.,  2.,  2.,  2., 16.,  1.,  1.,  1.,  1.,  8.,\n",
      "         1.,  1.,  1.,  8.,  1.,  1.,  8.,  1.,  8.,  8.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 100238/159274 [01:27<00:50, 1180.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: his name was, uh, Michael Zaidan, was supposed to have like written the screenplay or something\n",
      "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         1.,  0.,  0.,  0.,  2.,  2.,  1.,  0.,  3.,  0.,  2.,  2.,  0.,  0.,\n",
      "         0.,  5.,  0.,  0.,  0.,  2.,  2.,  1.,  0.,  3.,  0.,  2.,  2.,  0.,\n",
      "         0.,  0.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         4.,  2.,  0.,  6.,  0.,  4.,  4.,  0.,  0.,  0., 10.,  2.,  0.,  6.,\n",
      "         0.,  4.,  4.,  0.,  0.,  0., 10.,  0.,  3.,  0.,  2.,  2.,  0.,  0.,\n",
      "         0.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,  6.,  0.,\n",
      "         0.,  0., 15.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,  0., 10.,\n",
      "         0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 150139/159274 [02:11<00:09, 1010.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: They just don't work in concert.\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 2., 1., 0.,\n",
      "        1., 0., 0., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 2., 1., 0., 1., 0., 0., 1., 2., 2., 0., 2., 0.,\n",
      "        0., 2., 4., 0., 1., 0., 0., 1., 2., 0., 0., 0., 0., 0., 0., 0., 1., 2.,\n",
      "        0., 0., 0., 0., 0., 2.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159274/159274 [02:19<00:00, 1139.62it/s]\n",
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# FBoW feature vectors for train split (2nd order = 1st order concat with 2nd order)\n",
    "# Note that the concatenation might not be necessary? as it might be catched with as interactions in weights?\n",
    "train_input_features = []\n",
    "train_label_ids = []\n",
    "for (ex_index, example) in enumerate(tqdm(train_df)):\n",
    "    bow_feature = torch.zeros(len(second_order_bucket_index)) # up-to 2nd feature map\n",
    "    if sentence2_key is None:\n",
    "        sentence_combined = example[sentence1_key]\n",
    "    else:\n",
    "        sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "    sentence_tokens = modified_basic_tokenizer.tokenize(sentence_combined)\n",
    "    sentence_tokens = sentence_tokens[:max_length]\n",
    "    # first order here!\n",
    "#     for t in sentence_tokens:\n",
    "#         bow_feature[freq_bucket_map[token_frequency_map[t]]-1] += 1 # bucket count\n",
    "    # second order here!\n",
    "    for i in range(len(sentence_tokens)-1):\n",
    "        for j in range(i+1, len(sentence_tokens)):\n",
    "            t1 = sentence_tokens[i]\n",
    "            t2 = sentence_tokens[j]\n",
    "            if freq_bucket_map[token_frequency_map[t1]] != freq_bucket_map[token_frequency_map[t2]]:\n",
    "                index_tuple = [freq_bucket_map[token_frequency_map[t1]], freq_bucket_map[token_frequency_map[t2]]]\n",
    "                index_tuple.sort()\n",
    "                index_tuple = tuple(index_tuple)\n",
    "                bow_feature[second_order_bucket_index[index_tuple]] += 1 # pair of freq bucket count\n",
    "\n",
    "    if ex_index % 50000 == 0:\n",
    "        print(\"Example sentence: \" + sentence_combined)\n",
    "        print(bow_feature)\n",
    "    train_input_features.append(bow_feature)\n",
    "    train_label_ids.append(example[\"label\"])\n",
    "    \n",
    "train_input_features = torch.stack(train_input_features, dim=0)\n",
    "train_input_features = torch.tensor(train_input_features, dtype=torch.float)\n",
    "train_label_ids = torch.tensor(train_label_ids, dtype=torch.long)\n",
    "train_data = TensorDataset(train_input_features, train_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:04<00:00, 269.02it/s]\n",
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# FBoW feature vectors for validation split\n",
    "validation_input_features = []\n",
    "validation_label_ids = []\n",
    "for (ex_index, example) in enumerate(tqdm(eval_df)):\n",
    "    bow_feature = torch.zeros(len(second_order_bucket_index)) # up-to 2nd feature map\n",
    "    if sentence2_key is None:\n",
    "        sentence_combined = example[sentence1_key]\n",
    "    else:\n",
    "        sentence_combined = example[sentence1_key] + \" [SEP] \" + example[sentence2_key]\n",
    "    sentence_tokens = modified_basic_tokenizer.tokenize(sentence_combined)\n",
    "    sentence_tokens = sentence_tokens[:max_length]\n",
    "    # first order here!\n",
    "#     for t in sentence_tokens:\n",
    "#         bow_feature[freq_bucket_map[token_frequency_map[t]]-1] += 1 # bucket count\n",
    "    # second order here!\n",
    "    for i in range(len(sentence_tokens)-1):\n",
    "        for j in range(i+1, len(sentence_tokens)):\n",
    "            t1 = sentence_tokens[i]\n",
    "            t2 = sentence_tokens[j]\n",
    "            if freq_bucket_map[token_frequency_map[t1]] != freq_bucket_map[token_frequency_map[t2]]:\n",
    "                index_tuple = [freq_bucket_map[token_frequency_map[t1]], freq_bucket_map[token_frequency_map[t2]]]\n",
    "                index_tuple.sort()\n",
    "                index_tuple = tuple(index_tuple)\n",
    "                bow_feature[second_order_bucket_index[index_tuple]] += 1 # pair of freq bucket count\n",
    "    validation_input_features.append(bow_feature)\n",
    "    validation_label_ids.append(example[\"label\"])\n",
    "\n",
    "validation_input_features = torch.stack(validation_input_features, dim=0)\n",
    "validation_input_features = torch.tensor(validation_input_features, dtype=torch.float)\n",
    "validation_label_ids = torch.tensor(validation_label_ids, dtype=torch.long)\n",
    "validation_data = TensorDataset(validation_input_features, validation_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=per_device_train_batch_size*n_gpu)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=per_device_eval_batch_size*n_gpu, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart the model\n",
    "model = FBOWClassifier(len(validation_label_ids.unique()), len(second_order_bucket_index))\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "if n_gpu > 0 and not no_cuda:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-F1:  0.35341239044260425\n",
      "Macro-F1:  0.36794061382826637\n",
      "Macro-F1:  0.27629835188746127\n",
      "Macro-F1:  0.3039283012448564\n",
      "Macro-F1:  0.34237433529637756\n",
      "Macro-F1:  0.2971301162214186\n",
      "Macro-F1:  0.26879740438274685\n",
      "Macro-F1:  0.30046693385939593\n",
      "Macro-F1:  0.3063494829433335\n",
      "Macro-F1:  0.2976869603205971\n",
      "Macro-F1:  0.3093119233405902\n",
      "Macro-F1:  0.3114565815652904\n",
      "Macro-F1:  0.2792872691334453\n",
      "Macro-F1:  0.2736619125859923\n",
      "Macro-F1:  0.3050437997845208\n",
      "Macro-F1:  0.27920799604758106\n",
      "Macro-F1:  0.31547145215667977\n",
      "Macro-F1:  0.3057694220472013\n",
      "Macro-F1:  0.31140277092834595\n",
      "Macro-F1:  0.32925396256042067\n",
      "Macro-F1:  0.2828197157900147\n",
      "Macro-F1:  0.3335447214596112\n",
      "Macro-F1:  0.3052662524904352\n",
      "Macro-F1:  0.31166311322369106\n",
      "Macro-F1:  0.29579792731792315\n",
      "Macro-F1:  0.2481449115101256\n",
      "Macro-F1:  0.3073171716511163\n",
      "Macro-F1:  0.28881463236623883\n",
      "Macro-F1:  0.31166070156380593\n",
      "Macro-F1:  0.3264157870689836\n",
      "Macro-F1:  0.30742735585108033\n",
      "Macro-F1:  0.2765950382578643\n",
      "Macro-F1:  0.2715877775641542\n",
      "Macro-F1:  0.3362315124965398\n",
      "Macro-F1:  0.32844613392269434\n",
      "Macro-F1:  0.27896132514879207\n",
      "Macro-F1:  0.31415597259989164\n",
      "Macro-F1:  0.29857280160008787\n",
      "Macro-F1:  0.3231882678508006\n",
      "Macro-F1:  0.3423995450234905\n",
      "Macro-F1:  0.291492423234315\n",
      "Macro-F1:  0.28478642641898033\n",
      "Macro-F1:  0.29688640129910754\n",
      "Macro-F1:  0.35214631865410007\n",
      "Macro-F1:  0.298733042106283\n",
      "Macro-F1:  0.28803433543010776\n",
      "Macro-F1:  0.29700032650642544\n",
      "Macro-F1:  0.3422738850211373\n",
      "Macro-F1:  0.3014146075454677\n",
      "Macro-F1:  0.3164835209546973\n",
      "Macro-F1:  0.31960299738615433\n",
      "Macro-F1:  0.3053116689028423\n",
      "Macro-F1:  0.32680582874072917\n",
      "Macro-F1:  0.2956488338582297\n",
      "Macro-F1:  0.3431310184589103\n",
      "Macro-F1:  0.31959609452179966\n",
      "Macro-F1:  0.33529409514075953\n",
      "Macro-F1:  0.3310288491231111\n",
      "Macro-F1:  0.34223919533189684\n",
      "Macro-F1:  0.29774637049687286\n",
      "Macro-F1:  0.3202790163650805\n",
      "Macro-F1:  0.31760492640110916\n",
      "Macro-F1:  0.28523348209754357\n",
      "Macro-F1:  0.3180919694277658\n",
      "Macro-F1:  0.30054084986700214\n",
      "Macro-F1:  0.3061615902455082\n",
      "Macro-F1:  0.3240571288467426\n",
      "Macro-F1:  0.32471404268660226\n",
      "Macro-F1:  0.28718782820812083\n",
      "Macro-F1:  0.32609105180533754\n",
      "Macro-F1:  0.3453978043219789\n",
      "Macro-F1:  0.3418686744842077\n",
      "Macro-F1:  0.36312138090715207\n",
      "Macro-F1:  0.3265413245301663\n",
      "Macro-F1:  0.33043683019799147\n",
      "Macro-F1:  0.3090965166195339\n",
      "Macro-F1:  0.3198555538322664\n",
      "Macro-F1:  0.2968357297264672\n",
      "Macro-F1:  0.33237629380102834\n",
      "Macro-F1:  0.3004178769952773\n",
      "Macro-F1:  0.30783439380167077\n",
      "Macro-F1:  0.32741287359072285\n",
      "Macro-F1:  0.3086236856320447\n",
      "Macro-F1:  0.3078666252223075\n",
      "Macro-F1:  0.31442456861190443\n",
      "Macro-F1:  0.28328947269342625\n",
      "Macro-F1:  0.3183427289488626\n",
      "Macro-F1:  0.3032870912028525\n",
      "Macro-F1:  0.33571977510819884\n",
      "Macro-F1:  0.3049199226046923\n",
      "Macro-F1:  0.30913694447557377\n",
      "Macro-F1:  0.3140056878639556\n",
      "Macro-F1:  0.30608084806721186\n",
      "Macro-F1:  0.3364303634307883\n",
      "Macro-F1:  0.3254058963412545\n",
      "Macro-F1:  0.34555429259579107\n",
      "Macro-F1:  0.31196355636925527\n",
      "Macro-F1:  0.3205070668705478\n",
      "Macro-F1:  0.3183484184687558\n",
      "Macro-F1:  0.30848603598756497\n",
      "Macro-F1:  0.29899575139797424\n",
      "Macro-F1:  0.301457077001505\n",
      "Macro-F1:  0.3013931064498769\n",
      "Macro-F1:  0.2994844032830389\n",
      "Macro-F1:  0.33786243279117195\n",
      "Macro-F1:  0.3582035506244238\n",
      "Macro-F1:  0.2667754838473218\n",
      "Macro-F1:  0.3079603041158942\n",
      "Macro-F1:  0.3402591254095959\n",
      "Macro-F1:  0.3147578056875569\n",
      "Macro-F1:  0.3009806596524745\n",
      "Macro-F1:  0.3056514105761332\n",
      "Macro-F1:  0.3285493191174755\n",
      "Macro-F1:  0.3154252532998672\n",
      "Macro-F1:  0.3058234391593443\n",
      "Macro-F1:  0.34985770962561985\n",
      "Macro-F1:  0.3262546979356184\n",
      "Macro-F1:  0.2946402074981806\n",
      "Macro-F1:  0.3550524570658799\n",
      "Macro-F1:  0.3116120818159891\n",
      "Macro-F1:  0.30527137319950176\n",
      "Macro-F1:  0.3154346161521018\n",
      "Macro-F1:  0.3145888266114389\n",
      "Macro-F1:  0.3168116261009018\n",
      "Macro-F1:  0.31309784840674715\n",
      "Macro-F1:  0.3220596392112074\n",
      "Macro-F1:  0.32336728439729606\n",
      "Macro-F1:  0.3095980982236312\n",
      "Macro-F1:  0.3127132358019679\n",
      "Macro-F1:  0.32919099793309653\n",
      "Macro-F1:  0.3188008761704478\n",
      "Macro-F1:  0.3157820012954629\n",
      "Macro-F1:  0.3284748161572706\n",
      "Macro-F1:  0.3276087593053223\n",
      "Macro-F1:  0.3206540531332591\n",
      "Macro-F1:  0.3012199401782735\n",
      "Macro-F1:  0.3319318632405072\n",
      "Macro-F1:  0.28828436498335824\n",
      "Macro-F1:  0.3427668147419421\n",
      "Macro-F1:  0.33800544325597953\n",
      "Macro-F1:  0.2986671302485761\n",
      "Macro-F1:  0.2935682601694992\n",
      "Macro-F1:  0.3044755359769527\n",
      "Macro-F1:  0.32843795353189514\n",
      "Macro-F1:  0.3375224020484604\n",
      "Macro-F1:  0.35878781639905766\n",
      "Macro-F1:  0.30199562965763366\n",
      "Macro-F1:  0.3367307746622008\n",
      "Macro-F1:  0.31535980970491456\n",
      "Macro-F1:  0.301008267781758\n",
      "Best Macro-F1:  0.36794061382826637\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "num_train_epochs = 30\n",
    "max_score = -1\n",
    "for _ in range(int(num_train_epochs)):\n",
    "    \n",
    "    model.train()\n",
    "    # pbar = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if torch.cuda.is_available() and not no_cuda:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        input_features, label_ids = batch\n",
    "\n",
    "        if torch.cuda.is_available() and not no_cuda:\n",
    "            input_features = input_features.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "\n",
    "        loss, _ = model(input_features, labels=label_ids)\n",
    "\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        # pbar.set_postfix({'train_loss': loss.tolist()})\n",
    "\n",
    "        if global_step % 250 == 0:\n",
    "            logger.info(\"***** Evaluation Interval Hit *****\")\n",
    "            model.eval()\n",
    "            all_logits = []\n",
    "            all_label_ids = []\n",
    "            with torch.no_grad():\n",
    "                # pbar = tqdm(validation_dataloader, desc=\"Iteration\")\n",
    "                for step, batch in enumerate(validation_dataloader):\n",
    "                    if torch.cuda.is_available() and not no_cuda:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                    input_features, label_ids = batch\n",
    "                    \n",
    "                    if torch.cuda.is_available() and not no_cuda:\n",
    "                        input_features = input_features.to(device)\n",
    "                        label_ids = label_ids.to(device)\n",
    "                    \n",
    "                    loss, logits = model(input_features, labels=label_ids)\n",
    "                    logits = F.softmax(logits, dim=-1)\n",
    "                    logits = logits.detach().cpu().numpy()\n",
    "                    label_ids = label_ids.to('cpu').numpy()\n",
    "                    outputs = np.argmax(logits, axis=1)\n",
    "                    all_logits.append(outputs)\n",
    "                    all_label_ids.append(label_ids)\n",
    "                    \n",
    "            all_logits = np.concatenate(all_logits, axis=0)\n",
    "            all_label_ids = np.concatenate(all_label_ids, axis=0)\n",
    "            result_to_save = classification_report(all_label_ids, all_logits, digits=5, output_dict=True)\n",
    "            # print(classification_report(all_label_ids, all_logits, digits=5))\n",
    "            print(\"Macro-F1: \", result_to_save[\"macro avg\"][\"f1-score\"])\n",
    "            if result_to_save[\"macro avg\"][\"f1-score\"] > max_score:\n",
    "                max_score = result_to_save[\"macro avg\"][\"f1-score\"]\n",
    "                    \n",
    "        global_step += 1\n",
    "print(\"Best Macro-F1: \", max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2): 0,\n",
       " (1, 3): 1,\n",
       " (1, 4): 2,\n",
       " (1, 5): 3,\n",
       " (1, 6): 4,\n",
       " (1, 7): 5,\n",
       " (1, 8): 6,\n",
       " (1, 9): 7,\n",
       " (1, 10): 8,\n",
       " (1, 11): 9,\n",
       " (1, 12): 10,\n",
       " (1, 13): 11,\n",
       " (1, 14): 12,\n",
       " (1, 15): 13,\n",
       " (1, 16): 14,\n",
       " (1, 17): 15,\n",
       " (1, 18): 16,\n",
       " (1, 19): 17,\n",
       " (1, 20): 18,\n",
       " (1, 21): 19,\n",
       " (1, 22): 20,\n",
       " (1, 23): 21,\n",
       " (1, 24): 22,\n",
       " (2, 3): 23,\n",
       " (2, 4): 24,\n",
       " (2, 5): 25,\n",
       " (2, 6): 26,\n",
       " (2, 7): 27,\n",
       " (2, 8): 28,\n",
       " (2, 9): 29,\n",
       " (2, 10): 30,\n",
       " (2, 11): 31,\n",
       " (2, 12): 32,\n",
       " (2, 13): 33,\n",
       " (2, 14): 34,\n",
       " (2, 15): 35,\n",
       " (2, 16): 36,\n",
       " (2, 17): 37,\n",
       " (2, 18): 38,\n",
       " (2, 19): 39,\n",
       " (2, 20): 40,\n",
       " (2, 21): 41,\n",
       " (2, 22): 42,\n",
       " (2, 23): 43,\n",
       " (2, 24): 44,\n",
       " (3, 4): 45,\n",
       " (3, 5): 46,\n",
       " (3, 6): 47,\n",
       " (3, 7): 48,\n",
       " (3, 8): 49,\n",
       " (3, 9): 50,\n",
       " (3, 10): 51,\n",
       " (3, 11): 52,\n",
       " (3, 12): 53,\n",
       " (3, 13): 54,\n",
       " (3, 14): 55,\n",
       " (3, 15): 56,\n",
       " (3, 16): 57,\n",
       " (3, 17): 58,\n",
       " (3, 18): 59,\n",
       " (3, 19): 60,\n",
       " (3, 20): 61,\n",
       " (3, 21): 62,\n",
       " (3, 22): 63,\n",
       " (3, 23): 64,\n",
       " (3, 24): 65,\n",
       " (4, 5): 66,\n",
       " (4, 6): 67,\n",
       " (4, 7): 68,\n",
       " (4, 8): 69,\n",
       " (4, 9): 70,\n",
       " (4, 10): 71,\n",
       " (4, 11): 72,\n",
       " (4, 12): 73,\n",
       " (4, 13): 74,\n",
       " (4, 14): 75,\n",
       " (4, 15): 76,\n",
       " (4, 16): 77,\n",
       " (4, 17): 78,\n",
       " (4, 18): 79,\n",
       " (4, 19): 80,\n",
       " (4, 20): 81,\n",
       " (4, 21): 82,\n",
       " (4, 22): 83,\n",
       " (4, 23): 84,\n",
       " (4, 24): 85,\n",
       " (5, 6): 86,\n",
       " (5, 7): 87,\n",
       " (5, 8): 88,\n",
       " (5, 9): 89,\n",
       " (5, 10): 90,\n",
       " (5, 11): 91,\n",
       " (5, 12): 92,\n",
       " (5, 13): 93,\n",
       " (5, 14): 94,\n",
       " (5, 15): 95,\n",
       " (5, 16): 96,\n",
       " (5, 17): 97,\n",
       " (5, 18): 98,\n",
       " (5, 19): 99,\n",
       " (5, 20): 100,\n",
       " (5, 21): 101,\n",
       " (5, 22): 102,\n",
       " (5, 23): 103,\n",
       " (5, 24): 104,\n",
       " (6, 7): 105,\n",
       " (6, 8): 106,\n",
       " (6, 9): 107,\n",
       " (6, 10): 108,\n",
       " (6, 11): 109,\n",
       " (6, 12): 110,\n",
       " (6, 13): 111,\n",
       " (6, 14): 112,\n",
       " (6, 15): 113,\n",
       " (6, 16): 114,\n",
       " (6, 17): 115,\n",
       " (6, 18): 116,\n",
       " (6, 19): 117,\n",
       " (6, 20): 118,\n",
       " (6, 21): 119,\n",
       " (6, 22): 120,\n",
       " (6, 23): 121,\n",
       " (6, 24): 122,\n",
       " (7, 8): 123,\n",
       " (7, 9): 124,\n",
       " (7, 10): 125,\n",
       " (7, 11): 126,\n",
       " (7, 12): 127,\n",
       " (7, 13): 128,\n",
       " (7, 14): 129,\n",
       " (7, 15): 130,\n",
       " (7, 16): 131,\n",
       " (7, 17): 132,\n",
       " (7, 18): 133,\n",
       " (7, 19): 134,\n",
       " (7, 20): 135,\n",
       " (7, 21): 136,\n",
       " (7, 22): 137,\n",
       " (7, 23): 138,\n",
       " (7, 24): 139,\n",
       " (8, 9): 140,\n",
       " (8, 10): 141,\n",
       " (8, 11): 142,\n",
       " (8, 12): 143,\n",
       " (8, 13): 144,\n",
       " (8, 14): 145,\n",
       " (8, 15): 146,\n",
       " (8, 16): 147,\n",
       " (8, 17): 148,\n",
       " (8, 18): 149,\n",
       " (8, 19): 150,\n",
       " (8, 20): 151,\n",
       " (8, 21): 152,\n",
       " (8, 22): 153,\n",
       " (8, 23): 154,\n",
       " (8, 24): 155,\n",
       " (9, 10): 156,\n",
       " (9, 11): 157,\n",
       " (9, 12): 158,\n",
       " (9, 13): 159,\n",
       " (9, 14): 160,\n",
       " (9, 15): 161,\n",
       " (9, 16): 162,\n",
       " (9, 17): 163,\n",
       " (9, 18): 164,\n",
       " (9, 19): 165,\n",
       " (9, 20): 166,\n",
       " (9, 21): 167,\n",
       " (9, 22): 168,\n",
       " (9, 23): 169,\n",
       " (9, 24): 170,\n",
       " (10, 11): 171,\n",
       " (10, 12): 172,\n",
       " (10, 13): 173,\n",
       " (10, 14): 174,\n",
       " (10, 15): 175,\n",
       " (10, 16): 176,\n",
       " (10, 17): 177,\n",
       " (10, 18): 178,\n",
       " (10, 19): 179,\n",
       " (10, 20): 180,\n",
       " (10, 21): 181,\n",
       " (10, 22): 182,\n",
       " (10, 23): 183,\n",
       " (10, 24): 184,\n",
       " (11, 12): 185,\n",
       " (11, 13): 186,\n",
       " (11, 14): 187,\n",
       " (11, 15): 188,\n",
       " (11, 16): 189,\n",
       " (11, 17): 190,\n",
       " (11, 18): 191,\n",
       " (11, 19): 192,\n",
       " (11, 20): 193,\n",
       " (11, 21): 194,\n",
       " (11, 22): 195,\n",
       " (11, 23): 196,\n",
       " (11, 24): 197,\n",
       " (12, 13): 198,\n",
       " (12, 14): 199,\n",
       " (12, 15): 200,\n",
       " (12, 16): 201,\n",
       " (12, 17): 202,\n",
       " (12, 18): 203,\n",
       " (12, 19): 204,\n",
       " (12, 20): 205,\n",
       " (12, 21): 206,\n",
       " (12, 22): 207,\n",
       " (12, 23): 208,\n",
       " (12, 24): 209,\n",
       " (13, 14): 210,\n",
       " (13, 15): 211,\n",
       " (13, 16): 212,\n",
       " (13, 17): 213,\n",
       " (13, 18): 214,\n",
       " (13, 19): 215,\n",
       " (13, 20): 216,\n",
       " (13, 21): 217,\n",
       " (13, 22): 218,\n",
       " (13, 23): 219,\n",
       " (13, 24): 220,\n",
       " (14, 15): 221,\n",
       " (14, 16): 222,\n",
       " (14, 17): 223,\n",
       " (14, 18): 224,\n",
       " (14, 19): 225,\n",
       " (14, 20): 226,\n",
       " (14, 21): 227,\n",
       " (14, 22): 228,\n",
       " (14, 23): 229,\n",
       " (14, 24): 230,\n",
       " (15, 16): 231,\n",
       " (15, 17): 232,\n",
       " (15, 18): 233,\n",
       " (15, 19): 234,\n",
       " (15, 20): 235,\n",
       " (15, 21): 236,\n",
       " (15, 22): 237,\n",
       " (15, 23): 238,\n",
       " (15, 24): 239,\n",
       " (16, 17): 240,\n",
       " (16, 18): 241,\n",
       " (16, 19): 242,\n",
       " (16, 20): 243,\n",
       " (16, 21): 244,\n",
       " (16, 22): 245,\n",
       " (16, 23): 246,\n",
       " (16, 24): 247,\n",
       " (17, 18): 248,\n",
       " (17, 19): 249,\n",
       " (17, 20): 250,\n",
       " (17, 21): 251,\n",
       " (17, 22): 252,\n",
       " (17, 23): 253,\n",
       " (17, 24): 254,\n",
       " (18, 19): 255,\n",
       " (18, 20): 256,\n",
       " (18, 21): 257,\n",
       " (18, 22): 258,\n",
       " (18, 23): 259,\n",
       " (18, 24): 260,\n",
       " (19, 20): 261,\n",
       " (19, 21): 262,\n",
       " (19, 22): 263,\n",
       " (19, 23): 264,\n",
       " (19, 24): 265,\n",
       " (20, 21): 266,\n",
       " (20, 22): 267,\n",
       " (20, 23): 268,\n",
       " (20, 24): 269,\n",
       " (21, 22): 270,\n",
       " (21, 23): 271,\n",
       " (21, 24): 272,\n",
       " (22, 23): 273,\n",
       " (22, 24): 274,\n",
       " (23, 24): 275}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_order_bucket_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
